{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCgAUn7zW2F5"
   },
   "source": [
    "# Finetuning a CNN by using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XcjfbAX0vEq"
   },
   "source": [
    "In this notebook, I will finetune a pretrained CNN model by using our given dataset. First, we need to import PyTorch and check whether a GPU is available. This code has been run on Google Colab using a GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lLMVTYbW2F6",
    "outputId": "264092c3-1b39-48f4-f6cc-f10614c2c057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.10.0+cu111\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import copy\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O--WZPtBW2F8"
   },
   "source": [
    "The code below is for mounting the Google Drive directory that stores the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4FJ_YJAXc7V",
    "outputId": "6ce4cc78-4f34-4ab9-f123-6c0e43659d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at drive\n",
      "/content/drive/MyDrive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive', force_remount=True)\n",
    "%cd drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ5cSsZG1fPZ"
   },
   "source": [
    "Now, we're defining some hyperparameters. We selected the batch size as 64 because it turns out that's a sweet spot for our GPU constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mYyk3lIGW2F8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBA10jNvW2F-"
   },
   "source": [
    "At this part, we split our dataset into train and test, and then we applied some transformations such as resizing and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tWPningKW2F-"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./images\"\n",
    "num_classes = 10\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((200, 200)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "full_ds = torchvision.datasets.ImageFolder(\"./images\", transform=transform)\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "test_size = len(full_ds) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(full_ds, [train_size, test_size])\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "classes = [\"butterfly\", \"cat\", \"chicken\", \"cow\", \"dog\", \"elephant\", \"horse\", \"sheep\", \"spider\", \"squirrel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8F4gbBw2HML"
   },
   "source": [
    "Now, we're downloading the VGG19 model with pretrained weights, and then copying it into another variable, \"model_ft_all\". \n",
    "At this experiment, we'll have two neural networks:\n",
    "\n",
    "\n",
    "1.   \"model\": The weights of only two last fully connected (FC1 and FC2) layers will be finetuned.\n",
    "2.   \"model_ft_all\": The weights of all layers will be finetuned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQMngIyXW2GA",
    "outputId": "2b1bc243-aa9c-48e0-b8c7-467809546fcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg19(pretrained=True, progress=True)\n",
    "model_ft_all = copy.deepcopy(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDWZRXVA27Wc"
   },
   "source": [
    "First, we assign all parameters of the \"model\" network as not to be finetuned, because we're only interested in finetuning the last layers of that network.\n",
    "Then, we replace the last layer of both networks for classifying a set of 10 labels, in the end, we send those networks into our GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJqbekoUW2GA",
    "outputId": "3a29f787-5305-4673-cbb3-9e4e6305109f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "model.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
    "model_ft_all.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
    "model.to(device)\n",
    "model_ft_all.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2gbpxx8W2GA"
   },
   "source": [
    "At this part, we specify which layers of those networks will be finetuned, and then we define the corresponding optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Tg4AWcThLm08"
   },
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "params_to_update_ftall = []\n",
    "for name,param in model.named_parameters():\n",
    "  if name.startswith(\"classifier\"):\n",
    "    param.required_grad = True\n",
    "    params_to_update.append(param)\n",
    "  elif param.requires_grad == True:\n",
    "    params_to_update.append(param)\n",
    "for name,param in model_ft_all.named_parameters():\n",
    "  if param.requires_grad == True:\n",
    "    params_to_update_ftall.append(param)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "optimizer_ft_all = optim.SGD(params_to_update_ftall, lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3ees8eJ4foN"
   },
   "source": [
    "At this part, we define our training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BfmbD0eJ391P"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        curr_loss = 0.0\n",
    "        model.train() # setting the model for training\n",
    "        for i, data in enumerate(dataloader): # iterating over dataset\n",
    "          inputs, labels = data\n",
    "          inputs = inputs.to(device) # sending the input tensor into GPU\n",
    "          labels = labels.to(device) \n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outputs = model(inputs) # forward pass\n",
    "          loss = criterion(outputs, labels)\n",
    "          loss.backward() # backpropagation\n",
    "          optimizer.step()\n",
    "          curr_loss += loss.item()\n",
    "          if i % 5 == 4:    # print every 5 mini-batches\n",
    "              print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, curr_loss / 2000))\n",
    "              curr_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6JVcD3J4j4u"
   },
   "source": [
    "Now, it's time to start the finetuning process for both models. This part might take a long time. In our case, it took 52 minutes on Google Colab GPU runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmEIzYl3W2GB",
    "outputId": "529b08f3-9b1e-49ee-b52a-9c5fbf595af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 0.006\n",
      "[1,    10] loss: 0.004\n",
      "[1,    15] loss: 0.003\n",
      "[1,    20] loss: 0.002\n",
      "[1,    25] loss: 0.002\n",
      "[1,    30] loss: 0.001\n",
      "[1,    35] loss: 0.001\n",
      "[1,    40] loss: 0.001\n",
      "[1,    45] loss: 0.001\n",
      "[1,    50] loss: 0.001\n",
      "[1,    55] loss: 0.001\n",
      "[1,    60] loss: 0.001\n",
      "[1,    65] loss: 0.001\n",
      "[1,    70] loss: 0.001\n",
      "[1,    75] loss: 0.001\n",
      "[1,    80] loss: 0.001\n",
      "[1,    85] loss: 0.001\n",
      "[1,    90] loss: 0.001\n",
      "[1,    95] loss: 0.001\n",
      "[1,   100] loss: 0.001\n",
      "[1,   105] loss: 0.001\n",
      "[1,   110] loss: 0.001\n",
      "[1,   115] loss: 0.001\n",
      "[1,   120] loss: 0.001\n",
      "[1,   125] loss: 0.001\n",
      "[1,   130] loss: 0.001\n",
      "[1,   135] loss: 0.001\n",
      "[1,   140] loss: 0.001\n",
      "[1,   145] loss: 0.001\n",
      "[1,   150] loss: 0.001\n",
      "[1,   155] loss: 0.001\n",
      "[1,   160] loss: 0.001\n",
      "[1,   165] loss: 0.001\n",
      "[1,   170] loss: 0.001\n",
      "[1,   175] loss: 0.001\n",
      "[1,   180] loss: 0.001\n",
      "[1,   185] loss: 0.000\n",
      "[1,   190] loss: 0.001\n",
      "[1,   195] loss: 0.001\n",
      "[1,   200] loss: 0.001\n",
      "[1,   205] loss: 0.001\n",
      "[1,   210] loss: 0.001\n",
      "[1,   215] loss: 0.001\n",
      "[1,   220] loss: 0.001\n",
      "[1,   225] loss: 0.001\n",
      "[1,   230] loss: 0.001\n",
      "[1,   235] loss: 0.001\n",
      "[1,   240] loss: 0.000\n",
      "[1,   245] loss: 0.000\n",
      "[1,   250] loss: 0.001\n",
      "[1,   255] loss: 0.000\n",
      "[1,   260] loss: 0.001\n",
      "[1,   265] loss: 0.000\n",
      "[1,   270] loss: 0.001\n",
      "[1,   275] loss: 0.001\n",
      "[1,   280] loss: 0.001\n",
      "[1,   285] loss: 0.001\n",
      "[1,   290] loss: 0.001\n",
      "[1,   295] loss: 0.001\n",
      "[1,   300] loss: 0.001\n",
      "[1,   305] loss: 0.001\n",
      "[1,   310] loss: 0.001\n",
      "[1,   315] loss: 0.001\n",
      "[1,   320] loss: 0.001\n",
      "[1,   325] loss: 0.001\n",
      "[2,     5] loss: 0.000\n",
      "[2,    10] loss: 0.001\n",
      "[2,    15] loss: 0.000\n",
      "[2,    20] loss: 0.000\n",
      "[2,    25] loss: 0.001\n",
      "[2,    30] loss: 0.001\n",
      "[2,    35] loss: 0.000\n",
      "[2,    40] loss: 0.001\n",
      "[2,    45] loss: 0.001\n",
      "[2,    50] loss: 0.000\n",
      "[2,    55] loss: 0.001\n",
      "[2,    60] loss: 0.001\n",
      "[2,    65] loss: 0.001\n",
      "[2,    70] loss: 0.000\n",
      "[2,    75] loss: 0.001\n",
      "[2,    80] loss: 0.001\n",
      "[2,    85] loss: 0.001\n",
      "[2,    90] loss: 0.001\n",
      "[2,    95] loss: 0.001\n",
      "[2,   100] loss: 0.000\n",
      "[2,   105] loss: 0.000\n",
      "[2,   110] loss: 0.000\n",
      "[2,   115] loss: 0.000\n",
      "[2,   120] loss: 0.001\n",
      "[2,   125] loss: 0.000\n",
      "[2,   130] loss: 0.000\n",
      "[2,   135] loss: 0.001\n",
      "[2,   140] loss: 0.001\n",
      "[2,   145] loss: 0.000\n",
      "[2,   150] loss: 0.000\n",
      "[2,   155] loss: 0.001\n",
      "[2,   160] loss: 0.000\n",
      "[2,   165] loss: 0.000\n",
      "[2,   170] loss: 0.000\n",
      "[2,   175] loss: 0.001\n",
      "[2,   180] loss: 0.001\n",
      "[2,   185] loss: 0.001\n",
      "[2,   190] loss: 0.001\n",
      "[2,   195] loss: 0.000\n",
      "[2,   200] loss: 0.001\n",
      "[2,   205] loss: 0.001\n",
      "[2,   210] loss: 0.001\n",
      "[2,   215] loss: 0.000\n",
      "[2,   220] loss: 0.001\n",
      "[2,   225] loss: 0.001\n",
      "[2,   230] loss: 0.001\n",
      "[2,   235] loss: 0.000\n",
      "[2,   240] loss: 0.000\n",
      "[2,   245] loss: 0.001\n",
      "[2,   250] loss: 0.001\n",
      "[2,   255] loss: 0.000\n",
      "[2,   260] loss: 0.001\n",
      "[2,   265] loss: 0.001\n",
      "[2,   270] loss: 0.000\n",
      "[2,   275] loss: 0.001\n",
      "[2,   280] loss: 0.000\n",
      "[2,   285] loss: 0.001\n",
      "[2,   290] loss: 0.001\n",
      "[2,   295] loss: 0.000\n",
      "[2,   300] loss: 0.000\n",
      "[2,   305] loss: 0.001\n",
      "[2,   310] loss: 0.000\n",
      "[2,   315] loss: 0.000\n",
      "[2,   320] loss: 0.000\n",
      "[2,   325] loss: 0.000\n",
      "[1,     5] loss: 0.006\n",
      "[1,    10] loss: 0.004\n",
      "[1,    15] loss: 0.002\n",
      "[1,    20] loss: 0.001\n",
      "[1,    25] loss: 0.001\n",
      "[1,    30] loss: 0.001\n",
      "[1,    35] loss: 0.001\n",
      "[1,    40] loss: 0.001\n",
      "[1,    45] loss: 0.001\n",
      "[1,    50] loss: 0.001\n",
      "[1,    55] loss: 0.001\n",
      "[1,    60] loss: 0.001\n",
      "[1,    65] loss: 0.000\n",
      "[1,    70] loss: 0.001\n",
      "[1,    75] loss: 0.001\n",
      "[1,    80] loss: 0.000\n",
      "[1,    85] loss: 0.001\n",
      "[1,    90] loss: 0.000\n",
      "[1,    95] loss: 0.000\n",
      "[1,   100] loss: 0.000\n",
      "[1,   105] loss: 0.000\n",
      "[1,   110] loss: 0.001\n",
      "[1,   115] loss: 0.001\n",
      "[1,   120] loss: 0.000\n",
      "[1,   125] loss: 0.000\n",
      "[1,   130] loss: 0.001\n",
      "[1,   135] loss: 0.000\n",
      "[1,   140] loss: 0.000\n",
      "[1,   145] loss: 0.001\n",
      "[1,   150] loss: 0.000\n",
      "[1,   155] loss: 0.000\n",
      "[1,   160] loss: 0.000\n",
      "[1,   165] loss: 0.000\n",
      "[1,   170] loss: 0.000\n",
      "[1,   175] loss: 0.000\n",
      "[1,   180] loss: 0.000\n",
      "[1,   185] loss: 0.000\n",
      "[1,   190] loss: 0.000\n",
      "[1,   195] loss: 0.000\n",
      "[1,   200] loss: 0.000\n",
      "[1,   205] loss: 0.000\n",
      "[1,   210] loss: 0.000\n",
      "[1,   215] loss: 0.000\n",
      "[1,   220] loss: 0.000\n",
      "[1,   225] loss: 0.000\n",
      "[1,   230] loss: 0.000\n",
      "[1,   235] loss: 0.000\n",
      "[1,   240] loss: 0.001\n",
      "[1,   245] loss: 0.000\n",
      "[1,   250] loss: 0.000\n",
      "[1,   255] loss: 0.001\n",
      "[1,   260] loss: 0.000\n",
      "[1,   265] loss: 0.000\n",
      "[1,   270] loss: 0.000\n",
      "[1,   275] loss: 0.000\n",
      "[1,   280] loss: 0.001\n",
      "[1,   285] loss: 0.000\n",
      "[1,   290] loss: 0.001\n",
      "[1,   295] loss: 0.000\n",
      "[1,   300] loss: 0.000\n",
      "[1,   305] loss: 0.000\n",
      "[1,   310] loss: 0.000\n",
      "[1,   315] loss: 0.000\n",
      "[1,   320] loss: 0.000\n",
      "[1,   325] loss: 0.000\n",
      "[2,     5] loss: 0.000\n",
      "[2,    10] loss: 0.000\n",
      "[2,    15] loss: 0.000\n",
      "[2,    20] loss: 0.000\n",
      "[2,    25] loss: 0.000\n",
      "[2,    30] loss: 0.000\n",
      "[2,    35] loss: 0.000\n",
      "[2,    40] loss: 0.000\n",
      "[2,    45] loss: 0.000\n",
      "[2,    50] loss: 0.000\n",
      "[2,    55] loss: 0.000\n",
      "[2,    60] loss: 0.000\n",
      "[2,    65] loss: 0.000\n",
      "[2,    70] loss: 0.000\n",
      "[2,    75] loss: 0.000\n",
      "[2,    80] loss: 0.000\n",
      "[2,    85] loss: 0.000\n",
      "[2,    90] loss: 0.000\n",
      "[2,    95] loss: 0.000\n",
      "[2,   100] loss: 0.000\n",
      "[2,   105] loss: 0.000\n",
      "[2,   110] loss: 0.000\n",
      "[2,   115] loss: 0.000\n",
      "[2,   120] loss: 0.000\n",
      "[2,   125] loss: 0.000\n",
      "[2,   130] loss: 0.000\n",
      "[2,   135] loss: 0.000\n",
      "[2,   140] loss: 0.000\n",
      "[2,   145] loss: 0.000\n",
      "[2,   150] loss: 0.000\n",
      "[2,   155] loss: 0.000\n",
      "[2,   160] loss: 0.000\n",
      "[2,   165] loss: 0.000\n",
      "[2,   170] loss: 0.000\n",
      "[2,   175] loss: 0.000\n",
      "[2,   180] loss: 0.000\n",
      "[2,   185] loss: 0.000\n",
      "[2,   190] loss: 0.000\n",
      "[2,   195] loss: 0.000\n",
      "[2,   200] loss: 0.000\n",
      "[2,   205] loss: 0.000\n",
      "[2,   210] loss: 0.000\n",
      "[2,   215] loss: 0.000\n",
      "[2,   220] loss: 0.000\n",
      "[2,   225] loss: 0.000\n",
      "[2,   230] loss: 0.000\n",
      "[2,   235] loss: 0.000\n",
      "[2,   240] loss: 0.000\n",
      "[2,   245] loss: 0.000\n",
      "[2,   250] loss: 0.000\n",
      "[2,   255] loss: 0.000\n",
      "[2,   260] loss: 0.000\n",
      "[2,   265] loss: 0.000\n",
      "[2,   270] loss: 0.000\n",
      "[2,   275] loss: 0.000\n",
      "[2,   280] loss: 0.000\n",
      "[2,   285] loss: 0.000\n",
      "[2,   290] loss: 0.000\n",
      "[2,   295] loss: 0.000\n",
      "[2,   300] loss: 0.000\n",
      "[2,   305] loss: 0.000\n",
      "[2,   310] loss: 0.000\n",
      "[2,   315] loss: 0.000\n",
      "[2,   320] loss: 0.000\n",
      "[2,   325] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "train_model(model, trainloader, optimizer, 2)\n",
    "train_model(model_ft_all, trainloader, optimizer_ft_all, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHleYtoc4rO-"
   },
   "source": [
    "We save the weights that we trained into the disk to be able to reload the models in case of a failure below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ia42BkJdW2GC"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights_fc_finetune.pth')\n",
    "torch.save(model_ft_all.state_dict(), 'model_weights_full_finetune.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOIiMpy95bLQ"
   },
   "source": [
    "(Optional) Use code below for reloading the finetuned weights in case of a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0T_RrdLKh74g"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model_weights_fc_finetune.pth\"))\n",
    "model.eval()\n",
    "model_ft_all.load_state_dict(torch.load(\"model_weights_full_finetune.pth\"))\n",
    "model_ft_all.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DXmaQrnUl-jw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def test_model(model, dataloader):\n",
    "  model.to(device)\n",
    "  model.eval() # setting the model for evaluation\n",
    "  proc_dataloader = torch.utils.data.DataLoader(dataloader.dataset, \n",
    "                                                batch_size=batch_size, \n",
    "                                                num_workers=2,\n",
    "                                                drop_last=True)\n",
    "  preds_arr = np.array([])\n",
    "  labels_arr = np.array([])\n",
    "  dataset_size = len(proc_dataloader.dataset)\n",
    "  dataiter = iter(proc_dataloader)\n",
    "  for image, label in dataiter:\n",
    "    outputs = model(image.to(device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    preds_arr = np.concatenate((preds_arr, predicted.to(\"cpu\")))\n",
    "    labels_arr = np.concatenate((labels_arr, label.to(\"cpu\")))\n",
    "  return confusion_matrix(labels_arr, preds_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "i3mCetfKncfy"
   },
   "outputs": [],
   "source": [
    "mod_mx = test_model(model, testloader)\n",
    "mod_fa_mx = test_model(model_ft_all, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "hvPOUBGZgs_h",
    "outputId": "153b7afe-9491-477c-ca8d-b14d9c503213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[394   0   0   0   2   0   0   0   3   6]\n",
      " [  2 306   0   0  11   0   0   1   0   2]\n",
      " [  0   2 582   0   3   0   0   0   0   2]\n",
      " [  0   0   1 335   7   2  10  16   0   2]\n",
      " [  0   2   2   1 987   0   4   8   2   4]\n",
      " [  0   0   0   2   4 265   6   2   0   3]\n",
      " [  1   2   0   4   6   0 498   5   0   0]\n",
      " [  1   0   3   5   8   0   1 345   0   2]\n",
      " [ 18   0   1   0   3   0   1   2 944   6]\n",
      " [  0   2   2   0   2   0   0   1   0 340]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 842.4x595.44 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.heatmap(mod_fa_mx)\n",
    "print(mod_fa_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_SHrexGNWFC"
   },
   "source": [
    "As we can see from the heatmap, we can say our model is working pretty well and the heatmap failed to visualize the confusion matrix. The false amount of false classifications is relatively low, we can say our network is running well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7f1GHfPOXXP",
    "outputId": "55e3faa0-f026-4e18-c66a-ca1261fe5e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the \"model\": 93.84%\n",
      "Accuracy of the \"model_ft_all\": 95.85%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the \"model\": {:.2f}%'.format(np.mean(mod_mx.diagonal()/mod_mx.sum(axis=1) * 100)))\n",
    "print('Accuracy of the \"model_ft_all\": {:.2f}%'.format(np.mean(mod_fa_mx.diagonal()/mod_fa_mx.sum(axis=1) * 100)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "report.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e8ee52e26650204a08c885461d142fd8f9417f3debf9f56bc8c004b34840a697"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
